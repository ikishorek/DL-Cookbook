{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05.1 Generating Text in the Style of an Example Text - inference_p.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "7yWqdplWgoFm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "colab 에서 gutenberg 패키지를 사용하기 위해서는, libdb5.3-dev 선행 설치가 필요하다."
      ]
    },
    {
      "metadata": {
        "id": "PGLS_ZOe5Vnf",
        "colab_type": "code",
        "outputId": "e713a4c0-17d2-4c0c-8eb7-2ca82648c0e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "cell_type": "code",
      "source": [
        "!sudo apt install libdb5.3-dev"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  db5.3-doc\n",
            "The following NEW packages will be installed:\n",
            "  libdb5.3-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 10 not upgraded.\n",
            "Need to get 762 kB of archives.\n",
            "After this operation, 3,146 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdb5.3-dev amd64 5.3.28-13.1ubuntu1 [762 kB]\n",
            "Fetched 762 kB in 0s (7,484 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libdb5.3-dev.\n",
            "(Reading database ... 131322 files and directories currently installed.)\n",
            "Preparing to unpack .../libdb5.3-dev_5.3.28-13.1ubuntu1_amd64.deb ...\n",
            "Unpacking libdb5.3-dev (5.3.28-13.1ubuntu1) ...\n",
            "Setting up libdb5.3-dev (5.3.28-13.1ubuntu1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tiCi2V2G3bUq",
        "colab_type": "code",
        "outputId": "cc65ebbb-fcf7-470c-b30f-995a53f64495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install --upgrade setuptools\n",
        "!pip3 install gutenberg"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: setuptools in /usr/local/lib/python3.6/dist-packages (40.8.0)\n",
            "Collecting gutenberg\n",
            "  Downloading https://files.pythonhosted.org/packages/14/b1/6e99867c38e70d46366966a0a861c580377f38312cf9dbad38b82ed1823d/Gutenberg-0.7.0.tar.gz\n",
            "Collecting bsddb3>=6.1.0 (from gutenberg)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/fc/ebfbd4de236b493f9ece156f816c21df0ae87ccc22604c5f9b664efef1b9/bsddb3-6.2.6.tar.gz (239kB)\n",
            "\u001b[K    100% |████████████████████████████████| 245kB 17.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.6/dist-packages (from gutenberg) (0.16.0)\n",
            "Collecting rdflib-sqlalchemy>=0.3.8 (from gutenberg)\n",
            "  Downloading https://files.pythonhosted.org/packages/92/a2/bc580a51ac1f9680aa04da4b6e96d499903d6e606d2f78f02e73527799da/rdflib_sqlalchemy-0.3.8-py3-none-any.whl\n",
            "Collecting rdflib>=4.2.0 (from gutenberg)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/fe/630bacb652680f6d481b9febbb3e2c3869194a1a5fc3401a4a41195a2f8f/rdflib-4.2.2-py3-none-any.whl (344kB)\n",
            "\u001b[K    100% |████████████████████████████████| 348kB 26.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.5.1 in /usr/local/lib/python3.6/dist-packages (from gutenberg) (2.18.4)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from gutenberg) (40.8.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from gutenberg) (1.11.0)\n",
            "Requirement already satisfied: SQLAlchemy>=1.1.4 in /usr/local/lib/python3.6/dist-packages (from rdflib-sqlalchemy>=0.3.8->gutenberg) (1.2.18)\n",
            "Collecting alembic>=0.8.8 (from rdflib-sqlalchemy>=0.3.8->gutenberg)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/06/f1ae8393463c26f3dafa21eebac611088da02a26e1f1e23bd75fee2dbffe/alembic-1.0.7.tar.gz (1.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.0MB 21.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib>=4.2.0->gutenberg) (2.3.1)\n",
            "Collecting isodate (from rdflib>=4.2.0->gutenberg)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 22.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.1->gutenberg) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.1->gutenberg) (2018.11.29)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.1->gutenberg) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.1->gutenberg) (1.22)\n",
            "Collecting Mako (from alembic>=0.8.8->rdflib-sqlalchemy>=0.3.8->gutenberg)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/f3/67579bb486517c0d49547f9697e36582cd19dafb5df9e687ed8e22de57fa/Mako-1.0.7.tar.gz (564kB)\n",
            "\u001b[K    100% |████████████████████████████████| 573kB 27.2MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3 (from alembic>=0.8.8->rdflib-sqlalchemy>=0.3.8->gutenberg)\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from alembic>=0.8.8->rdflib-sqlalchemy>=0.3.8->gutenberg) (2.5.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic>=0.8.8->rdflib-sqlalchemy>=0.3.8->gutenberg) (1.1.1)\n",
            "Building wheels for collected packages: gutenberg, bsddb3, alembic, Mako\n",
            "  Building wheel for gutenberg (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/8e/cd/75/4bc6f16541a1b7a69b02168da567695b2271c23ac4a0a0a453\n",
            "  Building wheel for bsddb3 (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/11/b8/b3/fa84db10bf8c563e4ba1a72837a0946d123f12adb34b164bf5\n",
            "  Building wheel for alembic (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/f9/71/46/604b8a4f0a04b513f5799c974b556c1de19a70fde41d25672b\n",
            "  Building wheel for Mako (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/15/35/25/dbcb848832ccb1a4b4ad23f529badfd3bce9bf88017f7ca510\n",
            "Successfully built gutenberg bsddb3 alembic Mako\n",
            "Installing collected packages: bsddb3, Mako, python-editor, alembic, isodate, rdflib, rdflib-sqlalchemy, gutenberg\n",
            "Successfully installed Mako-1.0.7 alembic-1.0.7 bsddb3-6.2.6 gutenberg-0.7.0 isodate-0.6.0 python-editor-1.0.4 rdflib-4.2.2 rdflib-sqlalchemy-0.3.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_WCvUA0zQGpd",
        "colab_type": "code",
        "outputId": "a91e4bb1-d886-429d-ce87-0c894c7a7b8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-AJE6QUWg4AE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "시간 절약을 위해, gutenberg db file 들을 미리 다운로드 받아놓고, google drive 를 mount 하여 연결한다.\n",
        "\n",
        "* gutenberg db file 다운로드: https://drive.google.com/drive/folders/1Y6nMqJ-srDfflTuoniVdEzdWfkrShe4T\n",
        "\n",
        "*   gutenberg db file  기본 경로 : ~/gutenberg_data/metadata/metadata.db\n",
        "\n",
        "colab 상에서는, /content/gutenberg_data/metadata/metadata.db 에 위치하면 됨"
      ]
    },
    {
      "metadata": {
        "id": "fVrbBx3IQvqa",
        "colab_type": "code",
        "outputId": "58fccc58-061a-4d2f-da61-28725f299de0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lx3_jzJdR-W4",
        "colab_type": "code",
        "outputId": "abe89b2a-2d4c-437d-ba83-54e1330b2b77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "# unmount 를 원할 시 실행\n",
        "\n",
        "#!fusermount -u gdrive\n",
        "#!rmdir gdrive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fusermount: failed to unmount /content/gutenberg_data: Invalid argument\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uCz5DhOmg_8X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "/content/gdrive 에 google drive 를 mount 하고,\n",
        "\n",
        " 구글 드라이브 상의 /gutenberg/gutenberg_data 를 \n",
        " /content/gutenberg_data 위치로 symbolic link 연결한다\n"
      ]
    },
    {
      "metadata": {
        "id": "gZcDcY0xWPXs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ln -s /content/gdrive/My\\ Drive/gutenberg/gutenberg_data /content/gutenberg_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "36ZYgHb_VjKx",
        "colab_type": "code",
        "outputId": "24cfd53c-7749-495c-fbb6-d07982677121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -al /content/gutenberg_data/metadata/metadata.db"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access '/content/gutenberg_data/metadata/metadata.db': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rU6lpK_33ayM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "try:\n",
        "    GUTENBERG = True\n",
        "    from gutenberg.acquire import load_etext\n",
        "    from gutenberg.query import get_etexts, get_metadata\n",
        "    from gutenberg.acquire import get_metadata_cache\n",
        "    from gutenberg.acquire.text import UnknownDownloadUriException\n",
        "    from gutenberg.cleanup import strip_headers\n",
        "    from gutenberg._domain_model.exceptions import CacheAlreadyExistsException\n",
        "except ImportError:\n",
        "    GUTENBERG = False\n",
        "    print('Gutenberg is not installed. See instructions at https://pypi.python.org/pypi/Gutenberg')\n",
        "#import tensorflow as tf\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import TimeDistributed\n",
        "import tensorflow.keras.callbacks\n",
        "import tensorflow.keras.backend as K\n",
        "import scipy.misc\n",
        "import json\n",
        "\n",
        "import os, sys\n",
        "import re\n",
        "import PIL\n",
        "from PIL import ImageDraw\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.utils import get_file\n",
        "\n",
        "from IPython.display import clear_output, Image, display, HTML\n",
        "try:\n",
        "    from io import BytesIO\n",
        "except ImportError:\n",
        "    from StringIO import StringIO as BytesIO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EXsvn2uLhJoy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "미리 db 데이터를 넣어 놓아도,  cache.populate() 시 메타 데이타 땡겨오는데 시간이 꽤 걸린다.\n",
        "\n",
        "꼼수가 있는데, 아래 코드블럭을 run 하고 바로 stop 하면 메타데이타(get_metadata) 검색은 잘 안되지만,\n",
        "\n",
        "\n",
        "실제 텍스트 데이터 로드(load_etext) 는 잘 실행된다."
      ]
    },
    {
      "metadata": {
        "id": "fnVGqiNJ3ayP",
        "colab_type": "code",
        "outputId": "0a080995-25b1-4070-e3fa-3d31c86d34c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "if GUTENBERG:\n",
        "    cache = get_metadata_cache()\n",
        "    try:\n",
        "        cache.populate()\n",
        "    except CacheAlreadyExistsException as e:\n",
        "        print(e)\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "location: /root/gutenberg_data/metadata/metadata.db\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qQqO7VR3hNxM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "서적 ID를 기반으로 실제 서적 데이터를 땡겨온다.\n",
        "\n",
        "\n",
        "100 : 세익스피어 전집(희곡)\n",
        "\n",
        "2981 : 카사노바 회고집(에세이)\n",
        "\n",
        "[9296, 9798, 9881, 10462, 10799, 11364, 11889, 12180, 12398] : clarissa (여러 편의 편지 형태)\n",
        "\n",
        "\n",
        "학습 텍스트는 원본에서 목차 등 불필요한 텍스트를 발라내게 된다. (text.split 부분)"
      ]
    },
    {
      "metadata": {
        "id": "8n00slgP6YGb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "shakespeare_id = 100\n",
        "casanova_id = 2981 \n",
        "clarissa_ids = [9296, 9798, 9881, 10462, 10799, 11364, 11889, 12180, 12398]\n",
        "\n",
        "def load_etext_from(ids, filter_func):\n",
        "  etext = '\\n'.join([filter_func(strip_headers(load_etext(id))) \\\n",
        "                     for id in ids])\n",
        "  return etext"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h43THvuk-F84",
        "colab_type": "code",
        "outputId": "0b3e3b24-8c64-4e72-9d93-5fda413365a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "shakespeare = load_etext_from([shakespeare_id], lambda text: text.split('\\nTHE END', 1)[-1])\n",
        "print(len(shakespeare))\n",
        "shakespeare[:1000]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5528070\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n\\n\\nALL’S WELL THAT ENDS WELL\\n\\n\\nby William Shakespeare\\n\\n\\n\\nContents\\n\\nACT I\\nScene I. Rossillon. A room in the Countess’s palace.\\nScene II. Paris. A room in the King’s palace.\\nScene III. Rossillon. A Room in the Palace.\\n\\n\\nACT II\\nScene I. Paris. A room in the King’s palace.\\nScene II. Rossillon. A room in the Countess’s palace.\\nScene III. Paris. The King’s palace.\\nScene IV. Paris. The King’s palace.\\nScene V. Another room in the same.\\n\\n\\nACT III\\nScene I. Florence. A room in the Duke’s palace.\\nScene II. Rossillon. A room in the Countess’s palace.\\nScene III. Florence. Before the Duke’s palace.\\nScene IV. Rossillon. A room in the Countess’s palace.\\nScene V. Without the walls of Florence.\\nScene VI. Camp before Florence.\\nScene VII. Florence. A room in the Widow’s house.\\n\\n\\nACT IV\\nScene I. Without the Florentine camp.\\nScene II. Florence. A room in the Widow’s house.\\nScene III. The Florentine camp.\\nScene IV. Florence. A room in the Widow’s house.\\nScene V. Rossillon. A room in the Countess’s palace.\\n\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "nvAMCBz1Ci9Q",
        "colab_type": "code",
        "outputId": "b7621910-794c-4d13-95c9-115cc48999f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "casanova = load_etext_from([casanova_id], lambda text: text.split('\\nCASANOVA AT DUX', 1)[-1]) # from main contents\n",
        "print(len(casanova))\n",
        "casanova[:1000]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6685264\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n An Unpublished Chapter of History, By Arthur Symons\\n\\n I\\n The Memoirs of Casanova, though they have enjoyed the popularity of a bad reputation, have never had justice done to them by serious students of literature, of life, and of history. One English writer, indeed, Mr. Havelock Ellis, has realised that ‘there are few more delightful books in the world,’ and he has analysed them in an essay on Casanova, published in Affirmations, with extreme care and remarkable subtlety. But this essay stands alone, at all events in English, as an attempt to take Casanova seriously, to show him in his relation to his time, and in his relation to human problems. And yet these Memoirs are perhaps the most valuable document which we possess on the society of the eighteenth century; they are the history of a unique life, a unique personality, one of the greatest of autobiographies; as a record of adventures, they are more entertaining than Gil Blas, or Monte Cristo, or any of the imaginary travels, and'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "Zbur6dJQCjH6",
        "colab_type": "code",
        "outputId": "af4b739c-56e8-4cde-e4b1-c5abf1d0101c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "clarissa = load_etext_from(clarissa_ids, lambda text: text.split('\\nTHE HISTORY OF CLARISSA HARLOWE', 1)[-1]) # from main contents\n",
        "print(len(clarissa))\n",
        "clarissa[:1000]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5173348\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\n\\n\\n\\nLETTER I\\n\\nMISS ANNA HOWE, TO MISS CLARISSA HARLOWE JAN 10.\\n\\n\\nI am extremely concerned, my dearest friend, for the disturbances that\\nhave happened in your family. I know how it must hurt you to become\\nthe subject of the public talk: and yet, upon an occasion so generally\\nknown, it is impossible but that whatever relates to a young lady, whose\\ndistinguished merits have made her the public care, should engage every\\nbody's attention. I long to have the particulars from yourself; and of\\nthe usage I am told you receive upon an accident you could not help; and\\nin which, as far as I can learn, the sufferer was the aggressor.\\n\\nMr. Diggs, the surgeon, whom I sent for at the first hearing of the\\nrencounter, to inquire, for your sake, how your brother was, told me,\\nthat there was no danger from the wound, if there were none from the\\nfever; which it seems has been increased by the perturbation of his\\nspirits.\\n\\nMr. Wyerley drank tea with us yesterday; and though he is far from being\\npartial to \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "E_nUzg_Mkski",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "모델 저장에 쓸 파일명, char 임베딩 목록, chunk_size 등 메타데이타를 dict 로 묶어둔다."
      ]
    },
    {
      "metadata": {
        "id": "s0nqz37H3ayW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO : global char_to_index 추가 \n",
        "def get_chars_index(etext):\n",
        "  chars = list(sorted(set(etext)))\n",
        "  char_to_idx = {ch: idx for idx, ch in enumerate(chars)}\n",
        "  return chars, char_to_idx\n",
        "\n",
        "def generate_meta_from(etext, model_name, chunk_size=160):\n",
        "  etext_meta = {}\n",
        "  etext_meta['model_name'] = model_name\n",
        "  etext_meta['char'], etext_meta['char_to_idx'] = get_chars_index(etext)\n",
        "  etext_meta['chunk_size'] = chunk_size\n",
        "  return etext_meta\n",
        "  \n",
        "shakespeare_meta = generate_meta_from(shakespeare, 'shakespeare')\n",
        "casanova_meta = generate_meta_from(casanova, 'casanova')\n",
        "clarissa_meta = generate_meta_from(clarissa, 'clarissa')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pIG2LwgW3ayY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def char_rnn_model(chunk_size, num_chars, num_layers, num_nodes=512, dropout=0.1):\n",
        "    input = Input(shape=(chunk_size, num_chars), name='input')\n",
        "    prev = input\n",
        "    for i in range(num_layers):\n",
        "        lstm = LSTM(num_nodes, return_sequences=True, name='lstm_layer_%d' % (i + 1))(prev)\n",
        "        if dropout:\n",
        "            prev = Dropout(dropout)(lstm)\n",
        "        else:\n",
        "            prev = lstm\n",
        "    dense = TimeDistributed(Dense(num_chars, name='dense', activation='softmax'))(prev)\n",
        "    model = Model(inputs=[input], outputs=[dense])\n",
        "    optimizer = tf.train.RMSPropOptimizer(learning_rate=0.01)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0NP1IXaTkxH1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "기 학습되어 google drive 에 저장된 모델을 로드하여 inference 해본다.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "33BNza2wwZHX",
        "colab_type": "code",
        "outputId": "d3fc6bf5-64e4-4446-fadd-20d94eaf2bf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "# prediction from saved weights\n",
        "!ls -al /content/gutenberg_data/models/\n",
        "basepath = '/content/gutenberg_data/models/02/'\n",
        "\n",
        "def load_model(basepath, model_meta):\n",
        "  model = char_rnn_model(None, len(model_meta['char']), num_layers=2, num_nodes=640, dropout=0) \n",
        "  model.load_weights(basepath + \"/\" + model_meta['model_name'] + '_weights.h5')\n",
        "  return model\n",
        " \n",
        "prediction_models = {\n",
        "    'shakespeare' : load_model(basepath, shakespeare_meta),\n",
        "    'casanova' : load_model(basepath, casanova_meta),\n",
        "    'clarissa' : load_model(basepath, clarissa_meta),\n",
        "}\n",
        "prediction_models['shakespeare'].summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 8\n",
            "drwx------ 2 root root 4096 Mar  2 06:08 01\n",
            "drwx------ 2 root root 4096 Mar  2 06:09 02\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           (None, None, 94)          0         \n",
            "_________________________________________________________________\n",
            "lstm_layer_1 (LSTM)          (None, None, 640)         1881600   \n",
            "_________________________________________________________________\n",
            "lstm_layer_2 (LSTM)          (None, None, 640)         3279360   \n",
            "_________________________________________________________________\n",
            "time_distributed_4 (TimeDist (None, None, 94)          60254     \n",
            "=================================================================\n",
            "Total params: 5,221,214\n",
            "Trainable params: 5,221,214\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2ffQ8tgF3ayj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_output(model, training_text, model_meta, start_index=None, diversity=None, amount=400):\n",
        "    CHUNK_SIZE = model_meta['chunk_size']\n",
        "    if start_index is None:\n",
        "        start_index = random.randint(0, len(training_text) - CHUNK_SIZE - 1)\n",
        "    print(\"start_index : %s\" % start_index)\n",
        "    generated = training_text[start_index: start_index + CHUNK_SIZE]\n",
        "    yield generated + '#'\n",
        "    for i in range(amount):\n",
        "        x = np.zeros((1, len(generated), len(model_meta['char'])))\n",
        "        for t, char in enumerate(generated):\n",
        "            x[0, t, model_meta['char_to_idx'][char]] = 1.\n",
        "        preds = model.predict(x, verbose=0)[0]\n",
        "        if diversity is None:\n",
        "            next_index = np.argmax(preds[len(generated) - 1])\n",
        "        else:\n",
        "            preds = np.asarray(preds[len(generated) - 1]).astype('float64')\n",
        "            preds = np.log(preds) / diversity\n",
        "            exp_preds = np.exp(preds)\n",
        "            preds = exp_preds / np.sum(exp_preds)\n",
        "            probas = np.random.multinomial(1, preds, 1)\n",
        "            next_index = np.argmax(probas)     \n",
        "        next_char = model_meta['char'][next_index]\n",
        "        yield next_char\n",
        "\n",
        "        generated += next_char\n",
        "    return generated\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iaK6WZHel_eA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "카사노바 모델에 말을 시켜 보았다.\n",
        "\n",
        "diversity = None 으로 하였더니 뭔가 서두가 비슷한 말을 자꾸 한다.\n",
        "\n",
        "회고록으로 학습 시켜서 그런지 \"대화\" 문체가 많다.\n",
        "\n",
        "사실 소설문체로 endline 없이 결과가 쭉 나올 경우가 더 많은데, 읽기 힘들어서 이걸로 골랐다.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "G1kawo928ZwD",
        "colab_type": "code",
        "outputId": "ccc76fd7-8b42-436a-b65b-9830e9e1512e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "cell_type": "code",
      "source": [
        "for ch in generate_output(prediction_models['casanova'], casanova, model_meta=casanova_meta, amount=1000, start_index=6093314):\n",
        "    sys.stdout.write(ch)\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start_index : 6093314\n",
            "o to tell him that I wanted to start directly after dinner. This order acted on Betty like magic.\n",
            "\n",
            "“You mean to go as far as Centino, I suppose,” said the man. #“What do you mean?”\n",
            "\n",
            "“No, I should like to be in the same place.”\n",
            "\n",
            "“That will do nicely.”\n",
            "\n",
            "“I will do so, and I am sure you will be able to get a hundred thousand francs in company.”\n",
            "\n",
            "“I will do so, and I shall not let her come and see me.”\n",
            "\n",
            "“I will tell you the whole story.”\n",
            "\n",
            "“You are right, and I am sure you will be able to get a hundred thousand francs in company.”\n",
            "\n",
            "“I am delighted to hear it; the only condition is what I can do to consent to any other place. I told her that I should not have the honour of calling on you to-morrow, and I shall be delighted to see you.”\n",
            "\n",
            "“I am glad to hear it, but I will tell you where you are going.”\n",
            "\n",
            "“I am delighted to hear it; the only condition is what she will say when she sees me the whole affair.”\n",
            "\n",
            "“I am glad to hear it; but you must agree with me that I am not a liar and your lordship. I have not the slightest idea of the consequences, but the man is a woman of cold temper. I am sure that if you will come and see me stay here as long as you l\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q-IlmVhfmP3D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "세익스피어 모델에, 상기 카사노바의 시작문장을 똑같이 넣어서 말을 시켜 보았다.\n",
        "\n",
        "돈페드로와 클라우디오가 자꾸 Why 들어간 말을 한다(...)\n",
        "\n",
        "희곡 처럼 구성된 문장으로 나온다.\n"
      ]
    },
    {
      "metadata": {
        "id": "qrsOPjPcy1R_",
        "colab_type": "code",
        "outputId": "45fb2b46-b650-4f14-9bb0-7fd56b8b893c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "cell_type": "code",
      "source": [
        "for ch in generate_output(prediction_models['shakespeare'], casanova, model_meta=shakespeare_meta, amount=1000, start_index=6093314):\n",
        "    sys.stdout.write(ch)\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start_index : 6093314\n",
            "o to tell him that I wanted to start directly after dinner. This order acted on Betty like magic.\n",
            "\n",
            "“You mean to go as far as Centino, I suppose,” said the man. #I will tell you the\n",
            "sleeping of the country, and the seventh and fire; and there is a\n",
            "      better place than a star, and there is more to the worst of all\n",
            "      than the wind.\n",
            "\n",
            "\n",
            "      DON PEDRO.\n",
            "      Why, what a candle may be hang’d!\n",
            "\n",
            "\n",
            "      DON PEDRO.\n",
            "      Why, what a woman would that be the devil was set at the last,\n",
            "      and there is no time to be a sin-wounded beard, the contrary was here at the basest.\n",
            "\n",
            "\n",
            "      DON PEDRO.\n",
            "      Why, what a corrust house is this! What are you?\n",
            "\n",
            "\n",
            "      CLAUDIO.\n",
            "      I will not hear you speak to me, I was conceived against\n",
            "      you were better than your wisdom. I have been set in your way, and\n",
            "      he shall not live.\n",
            "\n",
            "\n",
            "      DON PEDRO.\n",
            "      Why, what is he?\n",
            "\n",
            "\n",
            "      DON PEDRO.\n",
            "      Why, what a corrust name!\n",
            "\n",
            "\n",
            "      BORACHIO.\n",
            "      I cannot tell what you will not come by any man.\n",
            "\n",
            "\n",
            "      DON PEDRO.\n",
            "      Why, what a woman would think so, I can tell you that I am a man whom I will not look upon me.\n",
            "\n",
            "\n",
            "      DON PEDRO.\n",
            "      Why, what’s the matter\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kft-cxL23azP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
